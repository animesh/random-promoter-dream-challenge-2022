{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95ccf061-467a-4193-abd2-79fd3f90e539",
   "metadata": {},
   "source": [
    "# DREAM Challenge - seq2exp by BMDS Lab, QUT\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaab291-2006-48f8-bb83-8f30bc2adc02",
   "metadata": {},
   "source": [
    "### Install dependencies, and separately, dna2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62769d32-6ae9-488e-9972-cd97de05a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch pandas numpy\n",
    "!git clone https://github.com/pnpnpn/dna2vec\n",
    "!pip install -r dna2vec/requirements.txt\n",
    "!pip install --upgrade numpy\n",
    "!pip install -e ./dna2vec\n",
    "!pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46941f-95a7-468b-803b-857216132feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall gensim\n",
    "!pip install git+https://github.com/RaRe-Technologies/gensim.git@78da89a29acc04af76a807a3693c08f09acf8ed8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b709df3-3438-4b8d-b955-51d0688cdc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify line 55 of /mnt/ssd1/seq2exp/gensim/gensim/models/ldamodel.py\n",
    "#  From: from scipy.misc import logsumexp\n",
    "#  To: from scipy.special import logsumexp\n",
    "\n",
    "!sed -i '55s/.*/    from scipy.special import logsumexp/' lib/python3.8/site-packages/gensim/models/ldamodel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bc53c-37d3-456c-8a81-7a40b84b233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dna2vec.multi_k_model import MultiKModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa2932-3522-4a7a-8e96-2b9e9cdd2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir pytorch-tensors-all\n",
    "!mkdir pytorch-tensors-test-set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1687c17-a5ac-442e-a354-cc757fb019a6",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d91ba1-5d2d-49c8-a700-6b1f0124512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dna2vec.multi_k_model import MultiKModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93afc2f-57cc-4ecc-9ff4-6cf2f7511160",
   "metadata": {},
   "source": [
    "### Prepare trimmed training sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104fdec5-efe1-4a49-adb5-dd93dc2ac63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq = 10000000\n",
    "i = 0\n",
    "\n",
    "with open('train_sequences.txt','r') as inFile, open('train_sequences.fasta','w') as outFile:\n",
    "    start = time()\n",
    "    \n",
    "    for line in inFile:\n",
    "        data = line.rstrip().split(\"\\t\") \n",
    "        ID = \"> \"+data[0]+\",\"+data[1]\n",
    "        trimmed_seq = data[0][17:-13]\n",
    "        if \"N\" in trimmed_seq:\n",
    "            continue\n",
    "\n",
    "        i+=1\n",
    "        \n",
    "        outFile.write(ID+\"\\n\"+trimmed_seq+\"\\n\")\n",
    "        \n",
    "        if i>=max_seq:\n",
    "            break\n",
    "\n",
    "    end = time()\n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9232ed6e-d0c6-49cc-8f2f-2ef5c39a1c6d",
   "metadata": {},
   "source": [
    "### Preparing dna2vec encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc79cac-b0a7-47cc-8de4-e86f729fe35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dna2vec model\n",
    "filepath = 'dna2vec-20161219-0153-k3to8-100d-10c-29320Mbp-sliding-Xat.w2v'\n",
    "if not os.path.exists(filepath):\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://github.com/pnpnpn/dna2vec/blob/master/pretrained/dna2vec-20161219-0153-k3to8-100d-10c-29320Mbp-sliding-Xat.w2v\", \n",
    "        \"dna2vec-20161219-0153-k3to8-100d-10c-29320Mbp-sliding-Xat.w2v\"\n",
    "    )\n",
    "mk_model = MultiKModel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16600e55-0ae6-4ef0-a2cd-edc805c93648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dna2vec\n",
    "' '.join(map(str, mk_model.vector('ATCG')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858d28af-9589-498c-9ad4-32de36965259",
   "metadata": {},
   "source": [
    "### Load sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633714ad-1e49-4246-8e7c-1e2163e9f569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the file is formatted as:\n",
    "'''\n",
    "> TGCATTTTTTTCACATCTCTTTGCCACGGGGTGAAGGATAGGATGGTATCCCCCCAGGCGAAGGACATCTGTGGGGATGGTTAGGTCAGGTGATATCGGTTACGGCTGTT,11\n",
    "TCTTTGCCACGGGGTGAAGGATAGGATGGTATCCCCCCAGGCGAAGGACATCTGTGGGGATGGTTAGGTCAGGTGATATC\n",
    "> TGCATTTTTTTCACATCTATGTTGCGTTAGAACGATATTGGAACACTTGTCAACAAGCTCATCTGAACTAATAGAGATGTATTCATAGGCTTCAGGTGGTTACGGCTGTT,6\n",
    "TATGTTGCGTTAGAACGATATTGGAACACTTGTCAACAAGCTCATCTGAACTAATAGAGATGTATTCATAGGCTTCAGGT\n",
    "...\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "with open('train_sequences.fasta', 'r') as fp:\n",
    "    data = {'sequence' : [], 'score' : []}\n",
    "    for line in fp:\n",
    "        fields = line.strip()[2:].split(',')\n",
    "        data['sequence'].append(fields[0])\n",
    "        data['score'].append(fields[1])\n",
    "        next(fp) # skip every even line\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df['sequence_trimmed'] = df['sequence'].str[17:-13]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfcd552-cd69-4ea5-8bce-399ec5bbe56e",
   "metadata": {},
   "source": [
    "### Function for computing embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c106315-d402-4d16-a1e9-259633034e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlapping_kmer_encoding_dna2vec(seq, k = 8):\n",
    "    # note: k is k until there is only k = [3,k] remaining positions in the sequence.\n",
    "\n",
    "    for i in range(0, len(seq) - k + 1):\n",
    "        sseq = seq[i:i+k]\n",
    "        if len(sseq) < 3 or len(sseq) > 8:\n",
    "            #print(f'error with `{sseq}`. length needs to be 3-8 (inc.)')\n",
    "            continue\n",
    "        #print( mk_model.vector(sseq))\n",
    "        yield mk_model.vector(sseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d77a1-e65b-4a04-bd01-e8b94b33deac",
   "metadata": {},
   "source": [
    "### Generate training Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3876b91-6a41-48e9-aeb6-a6ac9a629410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tensors\n",
    "\n",
    "set_size = 1000\n",
    "\n",
    "# value for n\n",
    "n = 300_000\n",
    "n = 300_000_000\n",
    "\n",
    "# values for k\n",
    "k = 3\n",
    "\n",
    "df_n = df.iloc[0:n, :]\n",
    "longest_sequence_trimmed = df_n['sequence_trimmed'].apply(len).max()\n",
    "print(f'longest_sequence_trimmed: {longest_sequence_trimmed}')\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "file_idx = 0\n",
    "\n",
    "for rowIdx, row in df_n.iterrows():\n",
    "    data = []\n",
    "\n",
    "    for embedIdx, embed in enumerate(overlapping_kmer_encoding_dna2vec(row['sequence_trimmed'], k=k)):\n",
    "        data.append(list(embed))\n",
    "\n",
    "    while len(data) < longest_sequence_trimmed - k + 1:\n",
    "        data.append(np.zeros(100))\n",
    "\n",
    "    X.append(data)\n",
    "    y.append(float(row['score']))\n",
    "    \n",
    "    if len(X) > 0 and len(X) % set_size == 0:\n",
    "\n",
    "        _X = torch.tensor(X, dtype=torch.float32)\n",
    "        _y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        print(file_idx, _X.shape, _y.shape)\n",
    "\n",
    "        torch.save(_X, f'jake/pytorch-tensors-all/Batch{file_idx:0>5}X.pt')\n",
    "        torch.save(_y, f'jake/pytorch-tensors-all/Batch{file_idx:0>5}y.pt')\n",
    "        \n",
    "        X = []\n",
    "        y = []\n",
    "        file_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675bc26-3e1f-4a13-b6bc-7c3d35f18e82",
   "metadata": {},
   "source": [
    "### Generate testing Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb5280-238f-49e6-ab1b-226f876601a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tensors, for test\n",
    "\n",
    "seqs = []\n",
    "with open('test_sequences.txt', 'r') as fp:\n",
    "    data = {'sequence' : [], 'score' : []}\n",
    "    for line in fp:\n",
    "        seqs.append(line.split('\\t')[0].strip()[17:-13])\n",
    "print(seqs[0:3])\n",
    "set_size = 1000\n",
    "k = 3\n",
    "\n",
    "longest_sequence_trimmed = max([\n",
    "    len(x)\n",
    "    for x in seqs\n",
    "])\n",
    "print(f'longest_sequence_trimmed: {longest_sequence_trimmed}')\n",
    "\n",
    "_train = torch.load('pytorch-tensors-all/Batch00001X.pt')\n",
    "longest_sequence_trimmed = _train.shape[1] + k - 1\n",
    "print(f'training tensor shape: {_train.shape}')\n",
    "print(f'forced longest_sequence_trimmed to be: {longest_sequence_trimmed - k + 1}, to match the training set')\n",
    "\n",
    "\n",
    "X = []\n",
    "\n",
    "file_idx = 0\n",
    "\n",
    "for rowIdx, seq in enumerate(seqs):\n",
    "    data = []\n",
    "\n",
    "    for embedIdx, embed in enumerate(overlapping_kmer_encoding_dna2vec(seq, k=k)):\n",
    "        data.append(list(embed))\n",
    "\n",
    "    while len(data) < longest_sequence_trimmed - k + 1:\n",
    "        data.append(np.zeros(100))\n",
    "\n",
    "    X.append(data)\n",
    "    \n",
    "    if len(X) > 0 and len(X) % set_size == 0 or rowIdx == (len(seqs) - 1):\n",
    "\n",
    "        _X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "        print(file_idx, _X.shape)\n",
    "\n",
    "        torch.save(_X, f'pytorch-tensors-test-set/Batch{file_idx:0>5}X.pt')\n",
    "        \n",
    "        X = []\n",
    "        file_idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c2e847-b685-4301-a441-2f5058c3864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX TITAN X\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch \n",
    "import pickle\n",
    "from torch import nn, Tensor \n",
    "import torch, math   \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import glob\n",
    "from utils import PositionalEncoding\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    print(torch.cuda.get_device_name(0)) \n",
    "\n",
    "class DREAMLazyTestData(TensorDataset):\n",
    "    def __init__(self, device=device):\n",
    "        super().__init__()\n",
    "        self.path = os.getcwd() + '/pytorch-tensors-test-set/'\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        zero_pad = (5 - len(str(item)))\n",
    "        basename = 'Batch' + ('0'*zero_pad) + str(item)\n",
    "       \n",
    "        Xfile = basename + 'X.pt'\n",
    "        X = t.load(self.path + Xfile).to(device)\n",
    "        return X\n",
    "    \n",
    "    def __len__(self):\n",
    "         return (len(glob.glob1(self.path, \"*.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b190ef-2f48-4532-bebd-cbcfc29a40d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = DREAMLazyTestData()\n",
    "myNet = torch.load(os.getcwd() + '/DREAMnet.pt')\n",
    "\n",
    "y_pred, y = [], []\n",
    "\n",
    "def evaluate(myModel, myData, has_labels = False):\n",
    "    nfiles = len(glob.glob1(myData.path, \"*.pt\"))\n",
    "    \n",
    "    for i in range(nfiles): \n",
    "        if i % 10 == 0: print(i)\n",
    "        \n",
    "        if has_labels: \n",
    "            test_X, _test_y = myData.__getitem__(i)\n",
    "            y.append(_test_y) \n",
    "        else:     \n",
    "            test_X = myData.__getitem__(i)\n",
    "        \n",
    "        with t.no_grad():  \n",
    "            y_pred.append(myModel(test_X).reshape(-1))\n",
    " \n",
    "    y = t.hstack(y).cpu().numpy() if has_labels == True else [] \n",
    "\n",
    "    return t.hstack(y_pred).cpu().numpy(), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ab89a6-f9b4-40f9-aa19-bea1b2ca4cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "y_pred, _ = evaluate(myNet, myData)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786501f9-76a1-481f-8f58-5f08e9f6ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import json\n",
    "\n",
    "test = np.genfromtxt(os.getcwd() + '/test_sequences.txt', dtype=None, encoding=None)\n",
    "assert test.shape == y_pred.shape\n",
    "\n",
    "pred_dict = {test[k][0]: float(y_pred[k]) for k in range(len(y_pred))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f708ac2-8f8c-4753-9ea8-b1289e9da7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.json', 'w') as fp:\n",
    "    json.dump(pred_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64ade519-ab95-490c-b7a6-60e04faedaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(list(zip( [test[k][0] for k in range(len(y_pred))], y_pred)))\n",
    "df.to_csv('submission.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b980ff04-cd95-4553-9d7f-b43c463ad716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): PositionalEncoding()\n",
      "  (1): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=100, out_features=1000, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (linear2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (2): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=100, out_features=1000, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (linear2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (3): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=100, out_features=1000, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (linear2): Linear(in_features=1000, out_features=100, bias=True)\n",
      "    (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.0, inplace=False)\n",
      "    (dropout2): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (4): Flatten(start_dim=1, end_dim=-1)\n",
      "  (5): Linear(in_features=11000, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(myNet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

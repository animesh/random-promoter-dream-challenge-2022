{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c329b576-d7de-4522-811d-e60b4e343237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c81e5b-b6a2-4251-a351-5696944973c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0     1\n",
      "0  TGCATTTTTTTCACATCTCTTTGCCACGGGGTGAAGGATAGGATGG...  11.0\n",
      "1  TGCATTTTTTTCACATCTATGTTGCGTTAGAACGATATTGGAACAC...   6.0\n",
      "2  TGCATTTTTTTCACATCTGTGAAGAATATCAGCTTTCAATCGTATT...   8.0\n",
      "3  TGCATTTTTTTCACATCAATCCGAGATATCTGTTGATAAACTTACC...   9.0\n",
      "4  TGCATTTTTTTCACATCAAGTTATCTGGTGTACGTTTTCTCGTATA...  12.0\n",
      "6739258\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_sequences.txt', sep = '\\t', header = None)\n",
    "print(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816a192b-f3ba-4dae-b231-b7bde26b8870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0          1\n",
      "0  TGCATTTTTTTCACATCATATGTAGGGTACGGATTAGAGTCGTGTT...   8.009074\n",
      "1  TGCATTTTTTTCACATCTGTAATGTCTACAGTGGATTCTGTTATGG...  12.000000\n",
      "2  TGCATTTTTTTCACATCTCCCTATGTGTTATATTACGTTGAACTTA...   8.213649\n",
      "3  TGCATTTTTTTCACATCCTATTACACATATGCGATTGGTTTCCGAG...  10.000000\n",
      "4  TGCATTTTTTTCACATCATCACGTTACAGTGTTGTGACTCTGTTGA...  10.280732\n",
      "                                                   0          1\n",
      "0  TGCATTTTTTTCACATCGTTCTGCATGTTCTCGGGAACTACCATCT...   7.272453\n",
      "1  TGCATTTTTTTCACATCTTCCTATGCTATACTTTGGTGTCGGGTAG...  10.000000\n",
      "2  TGCATTTTTTTCACATCTTGCCGTTCACAATGTCTTAGTATGGTCA...  13.891626\n",
      "3  TGCATTTTTTTCACATCCCGAGTTGATGTGACTTGCATCGTCCTAT...   8.549371\n",
      "4  TGCATTTTTTTCACATCCGTAGCATTTCAAGTTAAAGTCTAATCTA...  11.000000\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('data/train_0.txt', sep = '\\t', header = None)\n",
    "print(df1.head())\n",
    "\n",
    "df2 = pd.read_csv('data/val_0.txt', sep = '\\t', header = None)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c36c81e-0cf5-41b8-89ad-e201e61ac229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6739250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1) + len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "471bfddc-6ed2-47b7-bf8f-7285dc39a8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6739257.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)*0.9+len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8c1d58b-4a79-40f1-8a33-f6988ba1e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no common sequences across the training and validation data.\n"
     ]
    }
   ],
   "source": [
    "common_sequences = pd.merge(df1, df2, on=0, how='inner')\n",
    "\n",
    "# Check if there are any common sequences\n",
    "if not common_sequences.empty:\n",
    "    print(\"There are common sequences across the training and validation data.\")\n",
    "    print(common_sequences)\n",
    "else:\n",
    "    print(\"There are no common sequences across the training and validation data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a3f77b8-d756-4fcc-8462-9f5e9d0094ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0\n",
      "0  TGCATTTTTTTCACATCTATTACCTTACTAAGATTTACGTCATTTA...\n",
      "1  TGCATTTTTTTCACATCTGTAAGGTTGTCGGATTGCAGGTTATCTG...\n",
      "2  TGCATTTTTTTCACATCTTTGTCAAGATATGTAAACAGTTATCATC...\n",
      "3  TGCATTTTTTTCACATCAAATTTATCAACCGGAGGAGACCTCGTGC...\n",
      "4  TGCATTTTTTTCACATCATTTAAATTGGGCTTCGTCTTAAATTCAT...\n",
      "5  TGCATTTTTTTCACATCCATATTATTACATATCCTACTGCGTGTAT...\n",
      "6  TGCATTTTTTTCACATCGTGCTGCAACTTAGGGCTTTTGTGCAGAT...\n",
      "7  TGCATTTTTTTCACATCCGCTTCTTCCATATGCAAGTGTTTGCGCG...\n"
     ]
    }
   ],
   "source": [
    "# Load the sequences data from train_sequences.txt\n",
    "df = pd.read_csv('data/train_sequences.txt', sep='\\t', header=None)\n",
    "\n",
    "# Assuming df1 and df2 are already loaded from the previous steps\n",
    "\n",
    "# Extract sequences from each DataFrame\n",
    "sequences = set(df[0])  # Convert column with sequences to a set for df\n",
    "sequences_df1 = set(df1[0])  # Convert column with sequences to a set for df1\n",
    "sequences_df2 = set(df2[0])  # Convert column with sequences to a set for df2\n",
    "\n",
    "# Find sequences in df that are not in df1 or df2\n",
    "unique_sequences = sequences - sequences_df1 - sequences_df2\n",
    "\n",
    "# Convert the set back to a DataFrame if needed\n",
    "df_unique_sequences = pd.DataFrame(list(unique_sequences), columns=[0])\n",
    "\n",
    "# Display the unique sequences\n",
    "print(df_unique_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3141f908-c90e-4cf4-a3cc-7a99890390d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is df1 a subset of df?: True\n",
      "Is df2 a subset of df?: True\n",
      "Sequences present in df but not in df1 or df2:\n",
      "                                                         0     1\n",
      "374623   TGCATTTTTTTCACATCATTTAAATTGGGCTTCGTCTTAAATTCAT...  11.0\n",
      "569880   TGCATTTTTTTCACATCTATTACCTTACTAAGATTTACGTCATTTA...  14.0\n",
      "1223276  TGCATTTTTTTCACATCCATATTATTACATATCCTACTGCGTGTAT...  12.0\n",
      "3301795  TGCATTTTTTTCACATCAAATTTATCAACCGGAGGAGACCTCGTGC...   9.0\n",
      "3596294  TGCATTTTTTTCACATCGTGCTGCAACTTAGGGCTTTTGTGCAGAT...  13.0\n",
      "5073155  TGCATTTTTTTCACATCTTTGTCAAGATATGTAAACAGTTATCATC...  11.0\n",
      "6341772  TGCATTTTTTTCACATCTGTAAGGTTGTCGGATTGCAGGTTATCTG...  16.0\n",
      "6548840  TGCATTTTTTTCACATCCGCTTCTTCCATATGCAAGTGTTTGCGCG...  13.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df, df1, and df2 are already loaded from their respective files\n",
    "# df = pd.read_csv('data/train_sequences.txt', sep='\\t', header=None)\n",
    "# df1 = pd.read_csv('data/train_0.txt', sep='\\t', header=None)\n",
    "# df2 = pd.read_csv('data/val_0.txt', sep='\\t', header=None)\n",
    "\n",
    "# Check if df1 is a subset of df\n",
    "df1_in_df = pd.merge(df, df1, on=[0, 1], how='inner')\n",
    "is_df1_subset = len(df1_in_df) == len(df1)\n",
    "\n",
    "# Check if df2 is a subset of df\n",
    "df2_in_df = pd.merge(df, df2, on=[0, 1], how='inner')\n",
    "is_df2_subset = len(df2_in_df) == len(df2)\n",
    "\n",
    "# Print results\n",
    "print(f\"Is df1 a subset of df?: {is_df1_subset}\")\n",
    "print(f\"Is df2 a subset of df?: {is_df2_subset}\")\n",
    "\n",
    "# Additional check for sequences present in df but not in df1 or df2\n",
    "unique_to_df = pd.concat([df, df1, df2, df1, df2]).drop_duplicates(keep=False)\n",
    "\n",
    "print(\"Sequences present in df but not in df1 or df2:\")\n",
    "print(unique_to_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa5a91f6-f93c-4e18-830b-2fd4d93acf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is df1 a subset of df?: False\n",
      "Is df2 a subset of df?: False\n"
     ]
    }
   ],
   "source": [
    "# Check if df1 is a subset of df2\n",
    "df1_in_df2 = pd.merge(df2, df1, on=[0, 1], how='inner')\n",
    "is_df1_subset = len(df1_in_df2) == len(df1)\n",
    "\n",
    "# Check if df2 is a subset of df1\n",
    "df2_in_df1 = pd.merge(df1, df2, on=[0, 1], how='inner')\n",
    "is_df2_subset = len(df2_in_df1) == len(df2)\n",
    "\n",
    "# Print results\n",
    "print(f\"Is df1 a subset of df?: {is_df1_subset}\")\n",
    "print(f\"Is df2 a subset of df?: {is_df2_subset}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
